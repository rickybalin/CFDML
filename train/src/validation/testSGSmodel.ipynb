{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c717d040",
   "metadata": {},
   "source": [
    "# Validation for Anisotropic SGS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c3057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rbalin/opt/miniconda3/envs/ssim/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import math as m\n",
    "import torch\n",
    "from torch.nn.functional import mse_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import evtk\n",
    "import vtk\n",
    "from vtk.util import numpy_support as VN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62704098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for the model\n",
    "class SGS:\n",
    "    def __init__(self, data_path, model_path, crd_path=None, device=\"cpu\"):\n",
    "        self.data_path = data_path\n",
    "        self.crd_path = crd_path\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        self.test_data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.SGS = None\n",
    "        self.crd = None\n",
    "        self.model = None\n",
    "        self.y_pred_glob = None\n",
    "        self.min_val = np.zeros(6)\n",
    "        self.max_val = np.zeros(6)\n",
    "        self.eigvecs_aligned = None\n",
    "        self.SpO = None\n",
    "        self.Deltaij_norm = None\n",
    "        self.SGS_GM = None\n",
    "        self.new_outputs = None\n",
    "\n",
    "    # Load model\n",
    "    def load_model(self):\n",
    "        self.model = torch.jit.load(self.model_path+\"_jit.pt\", \n",
    "                                    map_location=torch.device(self.device))\n",
    "        tmp = np.loadtxt(self.model_path+\"_scaling.txt\")\n",
    "        self.min_val = tmp[:,0]\n",
    "        self.max_val = tmp[:,1]\n",
    "        \n",
    "    # Load inputs and outputs from file directly\n",
    "    def load_data(self):\n",
    "        extension = self.data_path.split(\".\")[-1]\n",
    "        #if \"npy\" in extension:\n",
    "        #    test_data = np.load(self.data_path)\n",
    "        #    self.y = test_data[:,:6]\n",
    "        #    self.X = test_data[:,6:]\n",
    "        #    self.crd = np.load(self.crd_path)\n",
    "        if \"vtu\" in extension or \"vtk\" in extension:\n",
    "            from vtk.util import numpy_support as VN\n",
    "            reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "            reader.SetFileName(self.data_path)\n",
    "            reader.Update()\n",
    "            output = reader.GetOutput()\n",
    "            self.X = np.hstack((VN.vtk_to_numpy(output.GetPointData().GetArray(\"input123\")),\n",
    "                                VN.vtk_to_numpy(output.GetPointData().GetArray(\"input456\"))))\n",
    "            self.y = np.hstack((VN.vtk_to_numpy(output.GetPointData().GetArray(\"output123\")),\n",
    "                                VN.vtk_to_numpy(output.GetPointData().GetArray(\"output456\"))))\n",
    "            self.SGS = np.hstack((VN.vtk_to_numpy(output.GetPointData().GetArray(\"SGS_diag\")),\n",
    "                                  VN.vtk_to_numpy(output.GetPointData().GetArray(\"SGS_offdiag\"))))\n",
    "            self.crd = VN.vtk_to_numpy(output.GetPoints().GetData())\n",
    "        return output\n",
    "    \n",
    "    # Compute inputs and outputs from raw data\n",
    "    def compute_data(self, scaling, alignment=\"vorticity\"):\n",
    "        extension = self.data_path.split(\".\")[-1]\n",
    "        if \"vtu\" in extension or \"vtk\" in extension:\n",
    "            reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "            reader.SetFileName(self.data_path)\n",
    "            reader.Update()\n",
    "            polydata = reader.GetOutput()\n",
    "            self.SGS = np.hstack((VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"SGS_diag\")),\n",
    "                                  VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"SGS_offdiag\"))))\n",
    "            self.crd = VN.vtk_to_numpy(polydata.GetPoints().GetData())\n",
    "            GradU = np.hstack((VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradUFilt\")),\n",
    "                            VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradVFilt\")),\n",
    "                            VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradZFilt\"))))\n",
    "            GradU = np.reshape(GradU, (-1,3,3))\n",
    "            Delta = VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"gij\"))\n",
    "            \n",
    "        nsamples = GradU.shape[0]\n",
    "        self.eigvecs_aligned = np.zeros((nsamples,3,3))\n",
    "        self.SpO = np.zeros((nsamples,))\n",
    "        self.Deltaij_norm = np.zeros((nsamples,))\n",
    "        self.y = np.zeros((nsamples,6))\n",
    "        self.X = np.zeros((nsamples,6))\n",
    "        Deltaij = np.zeros((3,3))\n",
    "        Sij = np.zeros((3,3))\n",
    "        Oij = np.zeros((3,3))\n",
    "        vort = np.zeros((3,))\n",
    "        vort_Sframe = np.zeros((3,))\n",
    "        tmp = np.zeros((3,3))\n",
    "        for i in range(nsamples):\n",
    "            Deltaij[0,0] = Delta[i,0]*scaling[0]\n",
    "            Deltaij[1,1] = Delta[i,1]*scaling[1]\n",
    "            Deltaij[2,2] = Delta[i,2]*scaling[2]\n",
    "            self.Deltaij_norm[i] = m.sqrt(Deltaij[0,0]**2 + Deltaij[1,1]**2 + Deltaij[2,2]**2)\n",
    "            Deltaij = Deltaij / (self.Deltaij_norm[i]+1.0e-14)\n",
    "            \n",
    "            Gij = np.matmul(GradU[i],Deltaij)\n",
    "            Sij[0,0] = Gij[0,0]\n",
    "            Sij[1,1] = Gij[1,1]\n",
    "            Sij[2,2] = Gij[2,2]\n",
    "            Sij[0,1] = 0.5*(Gij[0,1]+Gij[1,0])\n",
    "            Sij[0,2] = 0.5*(Gij[0,2]+Gij[2,0])\n",
    "            Sij[1,2] = 0.5*(Gij[1,2]+Gij[2,1])\n",
    "            Sij[1,0] = Sij[0,1]\n",
    "            Sij[2,0] = Sij[0,2]\n",
    "            Sij[2,1] = Sij[1,2]\n",
    "            Oij[0,1] = 0.5*(Gij[0,1]-Gij[1,0])\n",
    "            Oij[0,2] = 0.5*(Gij[0,2]-Gij[2,0])\n",
    "            Oij[1,2] = 0.5*(Gij[1,2]-Gij[2,1])\n",
    "            Oij[1,0] = -Oij[0,1]\n",
    "            Oij[2,0] = -Oij[0,2]\n",
    "            Oij[2,1] = -Oij[1,2]\n",
    "            vort[0] = -2*Oij[1,2]\n",
    "            vort[1] = -2*Oij[0,2]\n",
    "            vort[2] = -2*Oij[0,1]\n",
    "            Sij_norm = m.sqrt(Sij[0,0]**2+Sij[1,1]**2+Sij[2,2]**2 \\\n",
    "                          + 2*(Sij[0,1]**2+Sij[0,2]**2+Sij[1,2]**2))\n",
    "            vort_norm = m.sqrt(vort[0]**2 + vort[1]**2 + vort[2]**2)\n",
    "            self.SpO[i] = Sij_norm**2 + 0.5*vort_norm**2\n",
    "            \n",
    "            #evals, evecs = jacobi(Sij) \n",
    "            evals, evecs = la.eig(Sij)\n",
    "            if (alignment==\"vorticity\"):\n",
    "                vec = vort.copy()\n",
    "            elif (alignment==\"wall-normal\"):\n",
    "                vec = np.array([0,1,0])\n",
    "            else:\n",
    "                print(\"Alignment option not known, used default vorticity alignment\")\n",
    "                vec = vort.copy()\n",
    "            lda, eigvecs, self.eigvecs_aligned[i] = self.align_tensors(evals,evecs,vec)\n",
    "            \n",
    "            vort_Sframe[0] = np.dot(vort,self.eigvecs_aligned[i,:,0])\n",
    "            vort_Sframe[1] = np.dot(vort,self.eigvecs_aligned[i,:,1])\n",
    "            vort_Sframe[2] = np.dot(vort,self.eigvecs_aligned[i,:,2])\n",
    "            self.X[i,0] = lda[0] / (m.sqrt(self.SpO[i])+1.0e-14)\n",
    "            self.X[i,1] = lda[1] / (m.sqrt(self.SpO[i])+1.0e-14)\n",
    "            self.X[i,2] = lda[2] / (m.sqrt(self.SpO[i])+1.0e-14)\n",
    "            self.X[i,3] = vort_Sframe[0] / (m.sqrt(self.SpO[i])+1.0e-14)\n",
    "            self.X[i,4] = vort_Sframe[1] / (m.sqrt(self.SpO[i])+1.0e-14)\n",
    "            self.X[i,5] = 1.25e-5 / (self.Deltaij_norm[i]**2 * m.sqrt(self.SpO[i]) + 1.0e-14)\n",
    "        \n",
    "            tmp[0,0] = self.SGS[i,0] / (self.Deltaij_norm[i]**2 * self.SpO[i] + 1.0e-14)\n",
    "            tmp[1,1] = self.SGS[i,1] / (self.Deltaij_norm[i]**2 * self.SpO[i] + 1.0e-14)\n",
    "            tmp[2,2] = self.SGS[i,2] / (self.Deltaij_norm[i]**2 * self.SpO[i] + 1.0e-14)\n",
    "            tmp[0,1] = self.SGS[i,3] / (self.Deltaij_norm[i]**2 * self.SpO[i] + 1.0e-14)\n",
    "            tmp[0,2] = self.SGS[i,4] / (self.Deltaij_norm[i]**2 * self.SpO[i] + 1.0e-14)\n",
    "            tmp[1,2] = self.SGS[i,5] / (self.Deltaij_norm[i]**2 * self.SpO[i] + 1.0e-14)\n",
    "            tmp[1,0] = tmp[0,1]\n",
    "            tmp[2,0] = tmp[0,2]\n",
    "            tmp[2,1] = tmp[1,2]\n",
    "            tmp = np.matmul(np.transpose(self.eigvecs_aligned[i]),\n",
    "                           np.matmul(tmp,self.eigvecs_aligned[i]))\n",
    "            self.y[i,0] = tmp[0,0]\n",
    "            self.y[i,1] = tmp[1,1]\n",
    "            self.y[i,2] = tmp[2,2]\n",
    "            self.y[i,3] = tmp[0,1]\n",
    "            self.y[i,4] = tmp[0,2]\n",
    "            self.y[i,5] = tmp[1,2]\n",
    "            \n",
    "        return output\n",
    "        \n",
    "    # Run inference on all data for global metrics\n",
    "    def test_global(self, X_test=None, y_test=None):\n",
    "        if X_test and y_test:\n",
    "            X = X_test; y = y_test\n",
    "        else:\n",
    "            X = self.X; y = self.y; SGS = self.SGS\n",
    "        X_torch = torch.from_numpy(np.float32(X))\n",
    "        self.y_pred_glob = self.model(X_torch).detach().numpy()\n",
    "        self.y_pred_glob = self.undo_min_max(self.y_pred_glob)\n",
    "        mse_glob = self.MSE(y,self.y_pred_glob)\n",
    "        cc_glob = self.CC(y,self.y_pred_glob)\n",
    "        print(\"Inference on global data:\")\n",
    "        print(f\"Output MSE = {mse_glob:>8e}\")\n",
    "        print(f\"Output Corr. Coefficient = {cc_glob:>8e}\")\n",
    "        self.SGS_pred_glob = self.compute_SGS(self.y_pred_glob)\n",
    "        mse_glob = self.MSE(SGS,self.SGS_pred_glob)\n",
    "        cc_glob = self.CC(SGS,self.SGS_pred_glob)\n",
    "        print(f\"SGS MSE = {mse_glob:>8e}\")\n",
    "        print(f\"SGS Corr. Coefficient = {cc_glob:>8e}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Run inference one 1 wall-parallel layer at a time\n",
    "    def test_y_layers(self, X_test=None, y_test=None, crd_test=None):\n",
    "        if X_test and y_test and crd_test:\n",
    "            X = X_test; y = y_test; crd = crd_test\n",
    "        else:\n",
    "            X = self.X; y = self.y; crd = self.crd\n",
    "        crd_y = np.unique(crd[:,1])\n",
    "        ny = crd_y.size\n",
    "        mse_y = np.zeros_like(crd_y)\n",
    "        cc_y = np.zeros_like(crd_y)\n",
    "        for j in range(ny):\n",
    "            index = np.where(crd[:,1]==crd_y[j])\n",
    "            X_tmp = torch.from_numpy(np.float32(X[index]))\n",
    "            y_pred_tmp = self.model(X_tmp).detach().numpy()\n",
    "            y_pred_tmp = self.undo_min_max(y_pred_tmp)\n",
    "            mse_y[j] = self.MSE(y[index],y_pred_tmp)\n",
    "            cc_y[j] = self.CC(y[index],y_pred_tmp)\n",
    "        return crd_y, mse_y, cc_y\n",
    "\n",
    "    # Undo the model's min-max scaling\n",
    "    def undo_min_max(self,y):\n",
    "        for i in range(6):\n",
    "            y[:,i] = y[:,i] * (self.max_val[i] - self.min_val[i]) + self.min_val[i]\n",
    "        return y\n",
    "\n",
    "    # Deine MSE function\n",
    "    def MSE(self, y, y_pred):\n",
    "        return mse_loss(torch.from_numpy(y), torch.from_numpy(y_pred)).numpy()\n",
    "\n",
    "    # Define the Relative Root MSE function\n",
    "    def RRMSE(self,y,y_pred):\n",
    "        mse = mse_loss(torch.from_numpy(y), torch.from_numpy(y_pred)).numpy()\n",
    "        \n",
    "    \n",
    "    # Define Correlation Coefficient function\n",
    "    def CC(self, y, y_pred):\n",
    "        return np.corrcoef([np.ndarray.flatten(y),np.ndarray.flatten(y_pred)])[0][1]\n",
    "\n",
    "    # Align the eigenvalues and eignevectors according to the local vorticity\n",
    "    def align_tensors(self,evals,evecs,vec):\n",
    "        if (evals[0]<1.0e-8 and evals[1]<1.0e-8 and evals[2]<1.0e-8):\n",
    "            index = [0,1,2]\n",
    "        else:\n",
    "            index = np.flip(np.argsort(evals))\n",
    "        lda = evals[index]\n",
    "        vec_norm = m.sqrt(vec[0]**2 + vec[1]**2 + vec[2]**2)\n",
    "        vec = vec/vec_norm\n",
    "        eigvec = np.zeros((3,3))\n",
    "        eigvec[:,0] = evecs[:,index[0]]\n",
    "        eigvec[:,1] = evecs[:,index[1]]\n",
    "        eigvec[:,2] = evecs[:,index[2]]\n",
    "        eigvec_vort_aligned = eigvec.copy()\n",
    "        if (np.dot(vec,eigvec_vort_aligned[:,0]) < np.dot(vec,-eigvec_vort_aligned[:,0])):\n",
    "            eigvec_vort_aligned[:,0] = -eigvec_vort_aligned[:,0]\n",
    "        if (np.dot(vec,eigvec_vort_aligned[:,2]) < np.dot(vec,-eigvec_vort_aligned[:,2])):\n",
    "            eigvec_vort_aligned[:,2] = -eigvec_vort_aligned[:,2]\n",
    "        eigvec_vort_aligned[0,1] = (eigvec_vort_aligned[1,2]*eigvec_vort_aligned[2,0]) \\\n",
    "                               - (eigvec_vort_aligned[2,2]*eigvec_vort_aligned[1,0])\n",
    "        eigvec_vort_aligned[1,1] = (eigvec_vort_aligned[2,2]*eigvec_vort_aligned[0,0]) \\\n",
    "                               - (eigvec_vort_aligned[0,2]*eigvec_vort_aligned[2,0])\n",
    "        eigvec_vort_aligned[2,1] = (eigvec_vort_aligned[0,2]*eigvec_vort_aligned[1,0]) \\\n",
    "                               - (eigvec_vort_aligned[1,2]*eigvec_vort_aligned[0,0])\n",
    "        return lda, eigvec, eigvec_vort_aligned\n",
    "\n",
    "    # Compute the transformation needed to obtain the physical stresses\n",
    "    def compute_transformation(self, polydata, scaling, alignment=\"vorticity\"):\n",
    "        GradU = np.hstack((VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradUFilt\")),\n",
    "                            VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradVFilt\")),\n",
    "                            VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradZFilt\"))))\n",
    "        GradU = np.reshape(GradU, (-1,3,3))\n",
    "        Delta = VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"gij\"))\n",
    "        nsamples = GradU.shape[0]\n",
    "        self.eigvecs_aligned = np.zeros((nsamples,3,3))\n",
    "        self.SpO = np.zeros((nsamples,))\n",
    "        self.Deltaij_norm = np.zeros((nsamples,))\n",
    "        Deltaij = np.zeros((3,3))\n",
    "        Sij = np.zeros((3,3))\n",
    "        Oij = np.zeros((3,3))\n",
    "        vort = np.zeros((3,))\n",
    "        for i in range(nsamples):\n",
    "            Deltaij[0,0] = Delta[i,0]*scaling[0]\n",
    "            Deltaij[1,1] = Delta[i,1]*scaling[1]\n",
    "            Deltaij[2,2] = Delta[i,2]*scaling[2]\n",
    "            self.Deltaij_norm[i] = m.sqrt(Deltaij[0,0]**2 + Deltaij[1,1]**2 + Deltaij[2,2]**2)\n",
    "            Deltaij = Deltaij / (self.Deltaij_norm[i]+1.0e-14)\n",
    "            Gij = np.matmul(GradU[i],Deltaij)\n",
    "            Sij[0,0] = Gij[0,0]\n",
    "            Sij[1,1] = Gij[1,1]\n",
    "            Sij[2,2] = Gij[2,2]\n",
    "            Sij[0,1] = 0.5*(Gij[0,1]+Gij[1,0])\n",
    "            Sij[0,2] = 0.5*(Gij[0,2]+Gij[2,0])\n",
    "            Sij[1,2] = 0.5*(Gij[1,2]+Gij[2,1])\n",
    "            Sij[1,0] = Sij[0,1]\n",
    "            Sij[2,0] = Sij[0,2]\n",
    "            Sij[2,1] = Sij[1,2]\n",
    "            Oij[0,1] = 0.5*(Gij[0,1]-Gij[1,0])\n",
    "            Oij[0,2] = 0.5*(Gij[0,2]-Gij[2,0])\n",
    "            Oij[1,2] = 0.5*(Gij[1,2]-Gij[2,1])\n",
    "            Oij[1,0] = -Oij[0,1]\n",
    "            Oij[2,0] = -Oij[0,2]\n",
    "            Oij[2,1] = -Oij[1,2]\n",
    "            vort[0] = -2*Oij[1,2]\n",
    "            vort[1] = -2*Oij[0,2]\n",
    "            vort[2] = -2*Oij[0,1]\n",
    "            Sij_norm = m.sqrt(Sij[0,0]**2+Sij[1,1]**2+Sij[2,2]**2 \\\n",
    "                          + 2*(Sij[0,1]**2+Sij[0,2]**2+Sij[1,2]**2))\n",
    "            vort_norm = m.sqrt(vort[0]**2 + vort[1]**2 + vort[2]**2)\n",
    "            self.SpO[i] = Sij_norm**2 + 0.5*vort_norm**2\n",
    "            #evals, evecs = jacobi(Sij) \n",
    "            evals, evecs = la.eig(Sij)\n",
    "            if (alignment==\"vorticity\"):\n",
    "                vec = vort.copy()\n",
    "            elif (alignment==\"wall-normal\"):\n",
    "                vec = np.array([0,1,0])\n",
    "            else:\n",
    "                print(\"Alignment option not known, used default vorticity alignment\")\n",
    "                vec = vort.copy()\n",
    "            lda, eigvecs, self.eigvecs_aligned[i] = self.align_tensors(evals,evecs,vec)\n",
    "\n",
    "    # Compute physical stresses\n",
    "    def compute_SGS(self,y,index=None):\n",
    "        tmp = np.zeros((3,3))\n",
    "        nsamples = y.shape[0]\n",
    "        SGS_pred = np.zeros((nsamples,6))\n",
    "        for i in range(nsamples):\n",
    "            tmp[0,0] = y[i,0]\n",
    "            tmp[1,1] = y[i,1]\n",
    "            tmp[2,2] = y[i,2]\n",
    "            tmp[0,1] = y[i,3]\n",
    "            tmp[0,2] = y[i,4]\n",
    "            tmp[1,2] = y[i,5]\n",
    "            tmp[1,0] = tmp[0,1]\n",
    "            tmp[2,0] = tmp[0,2]\n",
    "            tmp[2,1] = tmp[1,2]\n",
    "            tmp = np.matmul(self.eigvecs_aligned[i],tmp)\n",
    "            tmp = np.matmul(tmp,np.transpose(self.eigvecs_aligned[i]))\n",
    "            SGS_pred[i,0] = tmp[0,0] * (self.Deltaij_norm[i]**2 * self.SpO[i])\n",
    "            SGS_pred[i,1] = tmp[1,1] * (self.Deltaij_norm[i]**2 * self.SpO[i])\n",
    "            SGS_pred[i,2] = tmp[2,2] * (self.Deltaij_norm[i]**2 * self.SpO[i])\n",
    "            SGS_pred[i,3] = tmp[0,1] * (self.Deltaij_norm[i]**2 * self.SpO[i])\n",
    "            SGS_pred[i,4] = tmp[0,2] * (self.Deltaij_norm[i]**2 * self.SpO[i])\n",
    "            SGS_pred[i,5] = tmp[1,2] * (self.Deltaij_norm[i]**2 * self.SpO[i])\n",
    "        return SGS_pred\n",
    "\n",
    "    # Compute the stress with the Gradient Model\n",
    "    def gradient_SGS_model(self, polydata, scaling):\n",
    "        GradU = np.hstack((VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradUFilt\")),\n",
    "                            VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradVFilt\")),\n",
    "                            VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"GradZFilt\"))))\n",
    "        GradU = np.reshape(GradU, (-1,3,3))\n",
    "        Delta = VN.vtk_to_numpy(polydata.GetPointData().GetArray(\"gij\"))\n",
    "        Delta[:,0] = Delta[:,0]*scaling[0]\n",
    "        Delta[:,1] = Delta[:,1]*scaling[1]\n",
    "        Delta[:,2] = Delta[:,2]*scaling[2]\n",
    "        nsamples = GradU.shape[0]\n",
    "        self.SGS_GM = np.zeros((nsamples,6))\n",
    "        for i in range(nsamples):\n",
    "            self.SGS_GM[i,0] = (Delta[i,0]**2 * GradU[i,0,0]**2 + \\\n",
    "                                Delta[i,1]**2 * GradU[i,0,1]**2 + \\\n",
    "                                Delta[i,2]**2 * GradU[i,0,2]**2) / 12 # 11\n",
    "            self.SGS_GM[i,1] = (Delta[i,0]**2 * GradU[i,1,0]**2 + \\\n",
    "                                Delta[i,1]**2 * GradU[i,1,1]**2 + \\\n",
    "                                Delta[i,2]**2 * GradU[i,1,2]**2) / 12 # 22\n",
    "            self.SGS_GM[i,2] = (Delta[i,0]**2 * GradU[i,2,0]**2 + \\\n",
    "                                Delta[i,1]**2 * GradU[i,2,1]**2 + \\\n",
    "                                Delta[i,2]**2 * GradU[i,2,2]**2) / 12 # 33\n",
    "            self.SGS_GM[i,3] = (Delta[i,0]**2 * GradU[i,0,0]*GradU[i,1,0] + \\\n",
    "                                Delta[i,1]**2 * GradU[i,0,1]*GradU[i,1,1] + \\\n",
    "                                Delta[i,2]**2 * GradU[i,0,2]*GradU[i,1,2]) / 12 # 12\n",
    "            self.SGS_GM[i,4] = (Delta[i,0]**2 * GradU[i,0,0]*GradU[i,2,0] + \\\n",
    "                                Delta[i,1]**2 * GradU[i,0,1]*GradU[i,2,1] + \\\n",
    "                                Delta[i,2]**2 * GradU[i,0,2]*GradU[i,2,2]) / 12 # 13\n",
    "            self.SGS_GM[i,5] = (Delta[i,0]**2 * GradU[i,1,0]*GradU[i,2,0] + \\\n",
    "                                Delta[i,1]**2 * GradU[i,1,1]*GradU[i,2,1] + \\\n",
    "                                Delta[i,2]**2 * GradU[i,1,2]*GradU[i,2,2]) / 12 # 23\n",
    "        print(\"Gradient Model on global data:\")\n",
    "        mse_glob = self.MSE(self.SGS,self.SGS_GM)\n",
    "        cc_glob = self.CC(self.SGS,self.SGS_GM)\n",
    "        print(f\"SGS MSE = {mse_glob:>8e}\")\n",
    "        print(f\"SGS Corr. Coefficient = {cc_glob:>8e}\")\n",
    "        print(\"\")\n",
    "        \n",
    "    # Save to vtk files for import into Paraview\n",
    "    def save_vtk(self, polydata, fname):\n",
    "        from vtk.numpy_interface import dataset_adapter as dsa\n",
    "        new = dsa.WrapDataObject(polydata)\n",
    "        new.PointData.append(self.X[:,:3], \"X123\")\n",
    "        new.PointData.append(self.X[:,3:], \"X456\")\n",
    "        new.PointData.append(self.y[:,:3], \"y123\")\n",
    "        new.PointData.append(self.y[:,3:], \"y456\")\n",
    "        new.PointData.append(self.y_pred_glob[:,:3], \"pred_output123\")\n",
    "        new.PointData.append(self.y_pred_glob[:,3:], \"pred_output456\")\n",
    "        new.PointData.append(self.SGS_pred_glob[:,:3], \"pred_SGS_diag\")\n",
    "        new.PointData.append(self.SGS_pred_glob[:,3:], \"pred_SGS_offdiag\")\n",
    "        if (self.SGS_GM is not None):\n",
    "            new.PointData.append(self.SGS_GM[:,:3], \"SGSGM_diag\")\n",
    "            new.PointData.append(self.SGS_GM[:,3:], \"SGSGM_offdiag\")\n",
    "        writer = vtk.vtkXMLUnstructuredGridWriter()\n",
    "        writer.SetFileName(fname)\n",
    "        writer.SetInputData(new.VTKObject)\n",
    "        writer.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88099ce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m base \u001b[38;5;241m=\u001b[39m SGS(data_path, model_path)\n\u001b[1;32m      5\u001b[0m base\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m----> 6\u001b[0m polydata \u001b[38;5;241m=\u001b[39m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m base\u001b[38;5;241m.\u001b[39mtest_global()\n\u001b[1;32m      8\u001b[0m base\u001b[38;5;241m.\u001b[39mgradient_SGS_model(polydata,[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 153\u001b[0m, in \u001b[0;36mSGS.compute_data\u001b[0;34m(self, scaling, alignment)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[i,\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[i,\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "base_path = \"/Users/rbalin/Documents/Research/ALCF_PostDoc/Conferences/PASC23/FlatPlate/Train/CRS_6-15_4d/\"\n",
    "data_path = base_path+\"train_data_noDamp/FlatPlate_ReTheta1000_6-15_ts30005_3x_noDamp_jacobi_test.vtu\"\n",
    "model_path = base_path+\"models/3x/NNmodel\"\n",
    "base = SGS(data_path, model_path)\n",
    "base.load_model()\n",
    "polydata = base.compute_data([3, 3, 3])\n",
    "base.test_global()\n",
    "base.gradient_SGS_model(polydata,[3, 3, 3])\n",
    "#crd_y, mse_y_off_bl_3x_3x, cc_y_off_bl_3x_3x =  off_bl_3x.test_y_layers()\n",
    "base.save_vtk(polydata,model_path+\"_predictions.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/rbalin/Documents/Research/ALCF_PostDoc/Conferences/PASC23/FlatPlate/Train/CRS_6-15_4d/\"\n",
    "data_path = base_path+\"train_data_noDamp/FlatPlate_ReTheta1000_6-15_ts30005_3x_noDamp_jacobi_test.vtu\"\n",
    "model_path = base_path+\"models/3x/py_inputs/NNmodel_w3\"\n",
    "w3 = SGS(data_path, model_path)\n",
    "w3.load_model()\n",
    "polydata = w3.compute_data([3, 3, 3],alignment=\"vorticity\")\n",
    "w3.test_global()\n",
    "w3.gradient_SGS_model(polydata,[3, 3, 3])\n",
    "#crd_y, mse_y_off_bl_3x_3x, cc_y_off_bl_3x_3x =  off_bl_3x.test_y_layers()\n",
    "w3.save_vtk(polydata,model_path+\"_predictions.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4334862",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/rbalin/Documents/Research/ALCF_PostDoc/Conferences/PASC23/FlatPlate/Train/CRS_6-15_4d/\"\n",
    "data_path = base_path+\"train_data_noDamp/FlatPlate_ReTheta1000_6-15_ts30005_3x_noDamp_jacobi_test.vtu\"\n",
    "model_path = \"/Users/rbalin/git-balin/data_driven_SGS_modeling/models/HIT/NNmodel_HIT\"\n",
    "HIT = SGS(data_path, model_path)\n",
    "HIT.load_model()\n",
    "polydata = HIT.compute_data([3, 3, 3],alignment=\"vorticity\")\n",
    "HIT.test_global()\n",
    "HIT.gradient_SGS_model(polydata,[3, 3, 3])\n",
    "#crd_y, mse_y_off_bl_3x_3x, cc_y_off_bl_3x_3x =  off_bl_3x.test_y_layers()\n",
    "HIT.save_vtk(polydata,model_path+\"_predictions.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437aa2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "axs[0].plot(crd_y, mse_y_off_bl_3x_3x, 's', label=\"off_bl_3x_3x\")\n",
    "#axs[0].plot(crd_y, mse_y_off_bl_6x_6x, 'o', label=\"off_bl_6x_6x\")\n",
    "#axs[0].plot(crd_y, mse_y_off_bl_3x_6x, 'o', label=\"off_bl_3x_6x\")\n",
    "axs[1].plot(crd_y, cc_y_off_bl_3x_3x, 's', label=\"off_bl_3x\")\n",
    "#axs[1].plot(crd_y, cc_y_off_bl_6x_6x, 'o', label=\"off_bl_6x\")\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].set_xscale(\"log\")\n",
    "#axs[1].set_yscale(\"log\")\n",
    "axs[1].set_xscale(\"log\")\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "fig.tight_layout(pad=3.0)\n",
    "axs[0].set_ylabel('MSE')\n",
    "axs[0].set_xlabel('y')\n",
    "axs[0].set_title('Mean Squared Error')\n",
    "axs[0].legend()\n",
    "axs[1].set_ylabel('Correlation Coefficient')\n",
    "axs[1].set_xlabel('y')\n",
    "axs[1].set_title('Correlation Coefficient')\n",
    "axs[1].legend()\n",
    "#plt.savefig(fig_name+\"_yerrors.png\", dpi='figure', format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6d22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
